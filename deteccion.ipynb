{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting models\n",
      "  Downloading models-0.9.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [8 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\samue\\AppData\\Local\\Temp\\pip-install-p71rofgc\\models_d1af294ba2a3418cb29f47e1c63b6b03\\setup.py\", line 25, in <module>\n",
      "          import models\n",
      "        File \"C:\\Users\\samue\\AppData\\Local\\Temp\\pip-install-p71rofgc\\models_d1af294ba2a3418cb29f47e1c63b6b03\\models\\__init__.py\", line 23, in <module>\n",
      "          from base import *\n",
      "      ModuleNotFoundError: No module named 'base'\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\samue\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Library import\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import models\n",
    "from functions import *\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Define and open externally pretrained models\n",
    "yv8n_model = YOLO(models.yolov8n)\n",
    "lp_model= YOLO(models.plate2)\n",
    "char_model = YOLO(models.chars3)\n",
    "\n",
    "\n",
    "# Define the path of the video to be analized, load it and print video properties (width, height, frames per second). Raise error if opening is not possible.\n",
    "video_path = 'parqueadero_minas.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Video opened. Video properties: Frames per second =\", fps, \"| Video size (height x width):\", height, \"x\", width)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error while opening video.\")\n",
    "    exit()\n",
    "#Defining we are working with a video currently (no stream)\n",
    "stream = False\n",
    "\n",
    "# Determine the vehicle classes that are to be recognized\n",
    "labels = {2:'car',3:'motorcycle',5:'bus',7:'truck'}\n",
    "labels_lp= {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'R', 27: 'S', 28: 'T', 29: 'U', 30: 'V', 31: 'W', 32: 'X', 33: 'Y', 34: 'Z'}\n",
    "\n",
    "# Create an empty list where all the recognized character identifications are going to be stored\n",
    "identified_characters = []\n",
    "\n",
    "\n",
    "# Create image analization loop until the end of the video\n",
    "while True:\n",
    "\n",
    "    # Read the loaded video until the end of the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Scale frame down to a lower resolution to achieve less necessary computational power and therefore faster vehicle recognition     \n",
    "    new_width = width\n",
    "    new_height = int(height * 9 / 16)\n",
    "    framehd = cv2.resize(frame, (0, 0), fx=1/3, fy=1/3)\n",
    "    frame640 = cv2.resize(framehd, (0, 0), fx=1/2, fy=1/2)\n",
    "    frame320 = cv2.resize(frame640, (0, 0), fx=1/2, fy=1/2)\n",
    "        \n",
    "    # Vehicle detection with loaded YOLOv8n model using the frame with reduced resolution for faster processing | parameter vid_stride defines framerate: every n frames 1 frame is being processed by YOLOv8n\n",
    "    vehicles_results = yv8n_model(frame320, imgsz=320, stream=stream, verbose=False, conf=0.5, classes=[2,3,5,7], vid_stride=2) \n",
    "    \n",
    "    # If no vehicle detection just continue with next iteration\n",
    "    if not vehicles_results: continue\n",
    "    \n",
    "    # Extracting the bounding box coordinates from the results of the vehicle detection model and converting them to a NumPy array of integers\n",
    "    if stream:\n",
    "        vehicles_detected = [result.boxes.cpu().numpy().data.astype(int) for result in vehicles_results][0]\n",
    "    else:\n",
    "        vehicles_results[0].plot()\n",
    "        vehicles_detected = vehicles_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "\n",
    "    # Now pass the coordinate of the bounding boxes of the recognized vehicle to the license plate detecion model.    \n",
    "    for vehicle in vehicles_detected:\n",
    "\n",
    "        # Recovering the 640 pixels image quality for the license plate detection \n",
    "        conf, cls = vehicle[-2:]\n",
    "        r = vehicle[:4] * 2\n",
    "        vehicle_frame = frame640[r[1]:r[3], r[0]:r[2]]\n",
    "    \n",
    "        # Detection of the license plates using the externally pretrained license plate recognition model\n",
    "        lp_results = lp_model(vehicle_frame, imgsz=640, stream=stream, verbose=False, conf=0.5, iou=0.4)\n",
    "        \n",
    "        # If no license plated detected just continue with next iteration\n",
    "        if not lp_results: continue\n",
    "        \n",
    "        # Extracting the bounding box coordinates from the results of the vehicle detection model and converting them to a NumPy array of integers\n",
    "        if stream:\n",
    "            lps_detected = [result.boxes.cpu().numpy().data.astype(int) for result in lp_results][0]\n",
    "        else:\n",
    "            lps_detected = lp_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "            \n",
    "        # Now pass the coordinate of the bounding boxes of the recognized license plate to the character identification model and iterate through them\n",
    "        for lp in lps_detected:\n",
    "            \n",
    "            # Extract from the original frame the license plate detection area and re-establish the original video quality\n",
    "            lp_conf = lp[-2]\n",
    "            rp = lp[:4] * 6\n",
    "            # Pre-selection: sort out all the images where the width-height ratio doesn´t fit the expected license plate ratio\n",
    "            if (rp[2] - rp[0])/(rp[3] - rp[1]) < 1.2 : continue\n",
    "            ro = r*6\n",
    "            lp_frame = frame[ro[1]:ro[3], ro[0]:ro[2]][rp[1]:rp[3], rp[0]:rp[2]]\n",
    "            \n",
    "\n",
    "            # Image pre-processing for better character recognition\n",
    "            # Define where to save the license plate images after preprocessing\n",
    "            subfolder_path = \"fotos\"\n",
    "            current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename_lp = f\"{subfolder_path}/license_plate_{current_time}.png\"\n",
    "            cv2.imwrite(filename_lp, lp_frame)\n",
    "            #Preprocessing way no.1 for yellow license plates\n",
    "            lp_frame_preprocessed_1_step_1 = preprocessing_1_segmentation(lp_frame)\n",
    "            lp_frame_preprocessed_2_step_1 = preprocessing_2_segmentation(lp_frame)\n",
    "            if lp_frame_preprocessed_2_step_1[:,:,2].mean() < 35:\n",
    "                lp_frame_preprocessed_1_step_2 = preprocessing_1_color_correction(lp_frame_preprocessed_1_step_1)\n",
    "                preprocessed_img_3channels = cv2.cvtColor(lp_frame_preprocessed_1_step_2, cv2.COLOR_GRAY2RGB)\n",
    "                #Save preprocessed license plate image 1\n",
    "                filename_ppi_1 = f\"{subfolder_path}/lp_ppi_1_{current_time}.png\"\n",
    "                cv2.imwrite(filename_ppi_1, lp_frame_preprocessed_1_step_2)\n",
    "            else:\n",
    "                #Preprocessing way no.2 for white license plates and converting it into a 3 channel img\n",
    "                lp_frame_preprocessed_2_step_2 = preprocessing_2_color_correction(lp_frame_preprocessed_2_step_1)\n",
    "                preprocessed_img_3channels = cv2.cvtColor(lp_frame_preprocessed_1_step_2, cv2.COLOR_GRAY2RGB)\n",
    "                #Save preprocessed license plate image 2\n",
    "                filename_ppi_2 = f\"{subfolder_path}/lp_ppi_2_{current_time}.png\"\n",
    "                cv2.imwrite(filename_ppi_2, lp_frame_preprocessed_2_step_2)\n",
    "                # print(\"Damaged license plate found.\")\n",
    "                \n",
    "            # Show the preprocessed image\n",
    "            cv2.imshow('Preprocessed license plate',preprocessed_img_3channels)\n",
    "\n",
    "            # Identify the characters on the license plate by the character identification model\n",
    "            char_results = char_model(preprocessed_img_3channels, imgsz=224, stream=stream, verbose=False, iou=0.8, max_det=6, conf=0.2)\n",
    "    \n",
    "            # If no characters detected and identified just continue with next iteration\n",
    "            if not char_results: continue\n",
    "\n",
    "            # Extracting the bounding box coordinates from the results of the character identification model and converting them to a NumPy array of integers\n",
    "            if stream:\n",
    "                chars_detected = [result.boxes.cpu().numpy().data.astype(int) for result in char_results][0]\n",
    "            else:\n",
    "                char_results[0].plot()\n",
    "                chars_detected = char_results[0].boxes.cpu().data.numpy().astype(int)\n",
    "            \n",
    "            # Extract the detected character prediction results if there are 6 characters identified\n",
    "            lp_text = ''\n",
    "            chars_detected_ordenados = sorted(chars_detected, key=lambda char: char[0])\n",
    "            for char in chars_detected_ordenados:\n",
    "                # print(char)\n",
    "                char_conf, char_cls = char[-2:]\n",
    "                rc = char[:4]\n",
    "                # Visualize the identified characters in a green box\n",
    "                cv2.rectangle(lp_frame, rc[:2], rc[2:], (0, 255, 0), 1)\n",
    "                lp_text+=labels_lp[char_cls]\n",
    "            if len(lp_text)==6:\n",
    "                print(lp_text)\n",
    "                # Append the recognized characters to the list identified_characters to save them later on\n",
    "                identified_characters.append(lp_text)\n",
    "            if x:=re.match(re.compile(r'^[A-Z]{3}\\d{2}[A-Z0-9]{1}$'), lp_text):\n",
    "                text = x[0]\n",
    "                print(text)\n",
    "                                \n",
    "            \n",
    "            ###------------Visualization of the detected vehicles, license plates and characters-------------###\n",
    "            # Visualize all the recognized characters\n",
    "            for char in chars_detected:\n",
    "                char_conf = char[-2]\n",
    "                rc = char[:4]\n",
    "                cv2.rectangle(lp_frame, rc[:2], rc[2:], (0, 255, 0), 1)\n",
    "            # Visualize all the recognized license plates \n",
    "            cv2.rectangle(vehicle_frame, lp[:4][:2], lp[:4][2:], (0, 255, 255), 1)\n",
    "            # Use for those recognitions an additional window showing the license plate frame\n",
    "            cv2.imshow('License Plate',lp_frame)\n",
    "\n",
    "        # Visualize the vehicle detection in the 640 pixels frame (detection of motorcycles in blue, any other vehicle detection in white)\n",
    "        if cls ==3 :\n",
    "            cv2.rectangle(frame640, r[:2], r[2:], (255, 0, 0), 2)\n",
    "        else:\n",
    "            cv2.rectangle(frame640, r[:2], r[2:], (255, 255, 255), 2)\n",
    "\n",
    "    # Show the 640 pixels frame while executing the detection              \n",
    "    cv2.imshow(\"result\", frame640)\n",
    "\n",
    "    # Define options to close the windows and object recognition with the key \"q\" and to pause it with the key \"p\"\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('p'):\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "# Clean finish: Release the captured frame and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the recognized license plates list to a txt-file\n",
    "# Open the file in write mode\n",
    "with open(\"recognitions.txt\", 'w') as file:\n",
    "    # Write each string from the list to the file\n",
    "    for item in identified_characters:\n",
    "        file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
